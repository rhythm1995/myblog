---
title: 数据挖掘——协同过滤
tags:
  - 数据挖掘
  - 算法
url: 83.html
id: 83
categories:
  - 数据挖掘
  - 算法
date: 2017-12-24 03:07:33
---

![](http://7xqgks.com1.z0.glb.clouddn.com/head-0046.jpg)

协同过滤概念
------

协同过滤（collabrative filtering）是最基础的数据挖掘推荐算法，起源是亚马逊的“爱你所爱”算法，即：”A和B兴趣类似，那么A喜欢的事物也会被B习惯“的原理来推荐的。网易云音乐也采用了这个算法做了一部分。 为方便下列叙述，定义以下概念：

*   1.已知喜好的用户A、他的兴趣为A.H、他喜好的事物为A.F；

*   2.需要给与推荐的用户B、兴趣为B.H、喜好为B.F。


协同过滤要点
------

# 1.寻找相似用户

如果A.H与B.H相似，可以定义为相似用户。其值可能是一组数据。 对于一维数据，做差即可。 考虑简单的二维情况，假设A.H有两个数据\[a1,b1\]，B.H有两个数据\[a2,b2\]。可以通过曼哈顿距离：

    |a1-a2|+|b1-b2|


计算出两者差距进行衡量。或者通过几何距离就行衡量。 如果是复杂的N维情况，其衡量可以一般化为明式距离： ![](http://img.my.csdn.net/uploads/201211/20/1353400356_6225.png) 可以看出，当P=1，计算的是曼哈顿距离；P=2，计算的是欧氏距离；P=无穷大，计算的是上确界距离。这个公式可以被用来定义相似用户的距离。改公司的python实现算法是：

    def moreMHDdis(a,b):
        sum = 0
        for i in range(len(a)):
            sum += abs(a[i]-b[i])
        return sum


# 2.用户评级差异

如果出现的数据是下列这样。 （定义满分10分，数字为给物品的评分）

Tables

物品A

物品B

物品C

用户A

8

7

9

用户B

10

2

9

用户C

6

6

7

可以看到用户A应该是给每项都打分接近的，用户B是给喜欢的很高，不喜欢的很低，用户C则是打分与A类似但评判标准却比较严格给的更加低一些。这种差异性如果不做处理，可能会给推荐系统带来问题。
对差异性的处理可以利用皮尔逊相关系数解决。这个系数的理解不复杂：我们如果把上述表做成折线图，可以他们之间有线性关系，皮尔逊相关系数就是代表**两组数的线性关系程度**的一个系数，它在二维情况下就是余弦。其计算公式是：

    A和B的协方差/(A的标准差∗B的标准差)


用python实现下：

    from math import sqrt

    def multipl(a,b):
        sumofab=0.0
        for i in range(len(a)):
            temp=a[i]*b[i]
            sumofab+=temp
        return sumofab

    def corrcoef(x,y):
        n=len(x)
        sum1=sum(x)
        sum2=sum(y)
        sumofxy=multipl(x,y)
        sumofx2 = sum([pow(i,2) for i in x])
        sumofy2 = sum([pow(j,2) for j in y])
        num=sumofxy-(float(sum1)*float(sum2)/n)
        den=sqrt((sumofx2-float(sum1**2)/n)*(sumofy2-float(sum2**2)/n))
        return num/den


# 稀疏性问题

协同过滤的稀疏性问题指的是，在一个超大的集合中：比如一百万本书中，A可能只读了一百本，B读了两百本，其中的交集可能绝大部分是空集。处理方案是对于稀疏度不同的数据，采用不同的距离进行计算。

*   如果数据稠密，比如所有属性没有空，那么使用欧氏距离或者曼哈顿距离是合理的。

*   如果数据受分数贬值（即不同用户使用不用的评级）影响，使用皮尔逊相关系数。

*   如果数据稀疏，使用余弦相似度


协同过滤应用
------

协同过滤是数据挖掘推荐算法的基础算法之一，在推荐系统中有广泛应用，计划之后补充一些demo。